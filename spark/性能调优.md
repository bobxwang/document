##### 数据本地化

```
new SparkConf().set("spark.locality.wait","100")
```

> 由DAGScheduler跟TaskScheduler共同负责数据的本地化

TaskSetManager中的Locality Level有如下五个级别

* Process-Local 进程本地化,task要计算的数据在同一个Executor中
* Node-Local 节点本地化,数据需要在不同进程间传递或从文件中读取 
* No-Pref 没有最佳位置一说,数据从哪访问都一样快,不需要位置优先,比如读取mysql的数据 
* Rack-Local 机架本地化,数据在同一机架的不同节点上
* Any 跨机架,最慢 

##### 资源分配

```
/usr/local/spark/bin/spark-submit \
--class cn.spark.sparktest.core.WordCountCluster \
--num-executors 3  \ 配置executor的数量
--executor-memory 100m  \ 配置每个executor的内存大小
--executor-cores 3   \ 配置每个executor的cpu core数量
--driver-memory 100m  \ 配置driver的内存（影响很大）
/usr/local/SparkTest-0.0.1-SNAPSHOT-jar-with-dependencies.jar \
```

##### 并行度

```
new SparkConf().set("spark.defalut.parallelism","500")
```

##### 数据倾斜

```
sc.set("spark.shuffle.file.buffer","64k")   //缓冲区默认大小为32k 
sc.set("spark.reducer.maxSizeInFlight","96M") //reduce端拉取数据的时候默认大小是48M 
```

